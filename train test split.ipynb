{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# h is the number of days before day (t)\n",
    "# r indicates how many days after day (t) --> target-day = day(t+r)\n",
    "# target could be number of deaths or number of confirmed \n",
    "def makeHistoricalData(h, r, target):\n",
    "        ''' in this code when h is 1, it means there is no history and we have just one column for each covariate\n",
    "        so when h is 0, we put h equal to 1, because when h is 0 that means there no history (as when h is 1) '''\n",
    "        if h == 0:\n",
    "                h = 1\n",
    "        \n",
    "        independantOfTimeData = pd.read_csv('fixed-data.csv')\n",
    "        timeDeapandantData = pd.read_csv('new-temporal-data.csv')\n",
    "\n",
    "        allData = pd.merge(independantOfTimeData, timeDeapandantData, on='county_fips')\n",
    "        allData = allData.sort_values(by=['date', 'county_fips'])\n",
    "        allData = allData.reset_index(drop=True)\n",
    "        # this columns are not numercal and wouldn't be included in correlation matrix, we store them to concatenate them later\n",
    "        notNumericlData = allData[['county_name', 'state_name', 'date']]\n",
    "\n",
    "        # next 2 lines arranges columns in order of correlations with target\n",
    "        ix = allData.corr().abs().sort_values(target, ascending=False).index\n",
    "        allData = allData.loc[:, ix]\n",
    "        allData = pd.concat([allData, notNumericlData], axis=1)\n",
    "\n",
    "        nameOfTimeDependantCovariates = timeDeapandantData.columns.values.tolist()\n",
    "        nameOfAllCovariates = allData.columns.values.tolist()\n",
    "\n",
    "        result = pd.DataFrame()  # we store historical data in this dataframe\n",
    "        totalNumberOfCounties = len(allData['county_fips'].unique())\n",
    "        totalNumberOfDays = len(allData['date'].unique())\n",
    "\n",
    "        # in this loop we make historical data\n",
    "        for name in nameOfAllCovariates:\n",
    "                # if covariate is time dependant\n",
    "                if name in nameOfTimeDependantCovariates and name not in ['date', 'county_fips']:\n",
    "                        temporalDataFrame = allData[[name]] # selecting column of the covariate that is being processed\n",
    "                        threshold = 0\n",
    "                        while threshold != h:\n",
    "                                # get value of covariate that is being processed in first (totalNumberOfDays-h-r+1) days\n",
    "                                temp = temporalDataFrame.head((totalNumberOfDays-h-r+1)*totalNumberOfCounties).copy().reset_index(drop=True)\n",
    "                                temp.rename(columns={name: (name + ' t-' + str(h-threshold-1))}, inplace=True) # renaming column\n",
    "                                result = pd.concat([result, temp], axis=1)\n",
    "                                # deleting the values in first day in temporalDataFrame dataframe (similiar to shift)\n",
    "                                temporalDataFrame = temporalDataFrame.iloc[totalNumberOfCounties:]\n",
    "                                threshold += 1\n",
    "                # if covariate is independant of time\n",
    "                elif name not in nameOfTimeDependantCovariates and name not in ['date', 'county_fips']:\n",
    "                        temporalDataFrame = allData[[name]]\n",
    "                        temp = temporalDataFrame.head((totalNumberOfDays-h-r+1)*totalNumberOfCounties).copy().reset_index(drop=True)\n",
    "                        result = pd.concat([result, temp], axis=1)\n",
    "\n",
    "        # next 3 lines is for adding FIPS code to final dataframe\n",
    "        temporalDataFrame = allData[['county_fips']]\n",
    "        temp = temporalDataFrame.head((totalNumberOfDays-h-r+1)*totalNumberOfCounties).copy().reset_index(drop=True)\n",
    "        result.insert(0, 'county_fips', temp)\n",
    "\n",
    "        # next 3 lines is for adding date of day (t) to final dataframe\n",
    "        temporalDataFrame = allData[['date']]\n",
    "        temporalDataFrame = temporalDataFrame[totalNumberOfCounties*(h-1):]\n",
    "        temp = temporalDataFrame.head((totalNumberOfDays-h-r+1)*totalNumberOfCounties).copy().reset_index(drop=True)\n",
    "        result.insert(1, 'date of day t', temp)\n",
    "\n",
    "        # next 3 lines is for adding target to final dataframe\n",
    "        temporalDataFrame = allData[[target]]\n",
    "        temporalDataFrame = temporalDataFrame.tail((totalNumberOfDays-h-r+1)*totalNumberOfCounties).reset_index(drop=True)\n",
    "        result.insert(1, 'Target', temporalDataFrame)\n",
    "        for i in result.columns:\n",
    "            if i.endswith('t-0'):\n",
    "                result.rename(columns={i: i[:-2]}, inplace=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def main():\n",
    "        h = 0\n",
    "        r = 14\n",
    "        target = 'confirmed'\n",
    "        #result = makeHistoricalData(h, r, target)\n",
    "        # Storing the result in a csv file\n",
    "        #result.to_csv('dataset_h=' + str(h) + '.csv', mode='w', index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from makeHistoricalData import makeHistoricalData\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sys import argv\n",
    "from math import floor\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################### split data to train, val, test\n",
    "def splitData(numberOfCounties, main_data, target, offset, j_offset):\n",
    "\n",
    "    X = pd.DataFrame()\n",
    "    y = pd.DataFrame()\n",
    "    for i in range(numberOfCounties + 1):\n",
    "        j = i * numberOfDays + j_offset\n",
    "        X = X.append(main_data.loc[j:j + offset - 1])\n",
    "        y = y.append(target.loc[j:j + offset - 1])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "########################################################### clean data\n",
    "def clean_data(data, numberOfSelectedCounties):\n",
    "\n",
    "    global numberOfDays\n",
    "    data = data.sort_values(by=['county_fips', 'date of day t'])\n",
    "    # select the number of counties we want to use\n",
    "    #numberOfSelectedCounties = numberOfCounties\n",
    "    if numberOfSelectedCounties == -1:\n",
    "        numberOfSelectedCounties = len(data['county_fips'].unique())\n",
    "\n",
    "    using_data = data[(data['county_fips'] <= data['county_fips'].unique()[numberOfSelectedCounties - 1])]\n",
    "    using_data = using_data.reset_index(drop=True)\n",
    "    main_data = using_data.drop(['county_fips', 'state_fips', 'state_name', 'county_name', 'date of day t'],\n",
    "                                axis=1)\n",
    "    # target = pd.DataFrame(main_data['Target'])\n",
    "    # main_data = main_data.drop(['Target'], axis=1)\n",
    "    # numberOfCounties = len(using_data['county_fips'].unique())\n",
    "    numberOfDays = len(using_data['date of day t'].unique())\n",
    "\n",
    "    return main_data\n",
    "\n",
    "\n",
    "########################################################### preprocess\n",
    "def preprocess(main_data, validationFlag):\n",
    "\n",
    "    target = pd.DataFrame(main_data['Target'])\n",
    "    main_data = main_data.drop(['Target'], axis=1)\n",
    "    # specify the size of train, validation and test sets\n",
    "    test_offset = 14\n",
    "    train_offset = floor(0.75 * (numberOfDays - test_offset))\n",
    "    val_offset = numberOfDays - (train_offset + test_offset)\n",
    "    t1 = time.time()\n",
    "\n",
    "\n",
    "    if validationFlag:     # validationFlag is 1 if we want to have a validation set and 0 otherwise\n",
    "        # add the functions to the multiprocessing object, loom\n",
    "        X_train_train,y_train_train = splitData(numberOfSelectedCounties, main_data, target, train_offset, 0)\n",
    "        X_train_train = X_train_train.reset_index(drop=True)\n",
    "        y_train_train = np.array(y_train_train).reshape(-1)\n",
    "        X_train_val,y_train_val = np.array(splitData(numberOfSelectedCounties, main_data, target, val_offset, train_offset))\n",
    "        X_train_val = X_train_val.reset_index(drop=True)\n",
    "        y_train_val = np.array(y_train_val).reshape(-1)\n",
    "        X_test,y_test = np.array(splitData(numberOfSelectedCounties, main_data, target, test_offset, train_offset + val_offset))\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_test = np.array(y_test).reshape(-1)\n",
    "\n",
    "        t2 = time.time()\n",
    "        #print('total time of data splitting: ', t2 - t1)\n",
    "\n",
    "        return X_train_train, X_train_val, X_test, y_train_train, y_train_val, y_test\n",
    "\n",
    "    else:\n",
    "        X_train ,y_train = splitData(numberOfSelectedCounties, main_data, target, train_offset + val_offset, 0)\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        y_train = np.array(y_train).reshape(-1)\n",
    "        X_test ,y_test = splitData(numberOfSelectedCounties, main_data, target, test_offset, train_offset + val_offset)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_test = np.array(y_test).reshape(-1)\n",
    "        \n",
    "        t2 = time.time()\n",
    "        #print('total time of data splitting: ', t2 - t1)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "r = 14\n",
    "target = 'confirmed'\n",
    "numberOfSelectedCounties = 500  # set to -1 for all the counties\n",
    "\n",
    "data = makeHistoricalData(h, r, target)\n",
    "data = clean_data(data, numberOfSelectedCounties)\n",
    "\n",
    "X_train_train, X_train_val, X_test, y_train_train, y_train_val, y_test = preprocess(data, 1) # with validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess(data, 0) # without validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
