{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makeHistoricalData import makeHistoricalData\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sys import argv\n",
    "from math import floor\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################### split data to train, val, test\n",
    "def splitData(numberOfCounties, main_data, target, offset, j_offset):\n",
    "\n",
    "    X = pd.DataFrame()\n",
    "    y = pd.DataFrame()\n",
    "    for i in range(numberOfCounties + 1):\n",
    "        j = i * numberOfDays + j_offset\n",
    "        X = X.append(main_data.loc[j:j + offset - 1])\n",
    "        y = y.append(target.loc[j:j + offset - 1])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "########################################################### clean data\n",
    "def clean_data(data, numberOfSelectedCounties):\n",
    "\n",
    "    global numberOfDays\n",
    "    data = data.sort_values(by=['county_fips', 'date of day t'])\n",
    "    # select the number of counties we want to use\n",
    "    #numberOfSelectedCounties = numberOfCounties\n",
    "    if numberOfSelectedCounties == -1:\n",
    "        numberOfSelectedCounties = len(data['county_fips'].unique())\n",
    "\n",
    "    using_data = data[(data['county_fips'] <= data['county_fips'].unique()[numberOfSelectedCounties - 1])]\n",
    "    using_data = using_data.reset_index(drop=True)\n",
    "    main_data = using_data.drop(['county_fips', 'state_fips', 'state_name', 'county_name', 'date of day t'],\n",
    "                                axis=1)\n",
    "    # target = pd.DataFrame(main_data['Target'])\n",
    "    # main_data = main_data.drop(['Target'], axis=1)\n",
    "    # numberOfCounties = len(using_data['county_fips'].unique())\n",
    "    numberOfDays = len(using_data['date of day t'].unique())\n",
    "\n",
    "    return main_data\n",
    "\n",
    "\n",
    "########################################################### preprocess\n",
    "def preprocess(main_data, validationFlag):\n",
    "\n",
    "    target = pd.DataFrame(main_data['Target'])\n",
    "    main_data = main_data.drop(['Target'], axis=1)\n",
    "    # specify the size of train, validation and test sets\n",
    "    test_offset = 14\n",
    "    train_offset = floor(0.75 * (numberOfDays - test_offset))\n",
    "    val_offset = numberOfDays - (train_offset + test_offset)\n",
    "    t1 = time.time()\n",
    "\n",
    "\n",
    "    if validationFlag:     # validationFlag is 1 if we want to have a validation set and 0 otherwise\n",
    "        # add the functions to the multiprocessing object, loom\n",
    "        X_train_train,y_train_train = splitData(numberOfSelectedCounties, main_data, target, train_offset, 0)\n",
    "        X_train_train = X_train_train.reset_index(drop=True)\n",
    "\n",
    "        X_train_val,y_train_val = np.array(splitData(numberOfSelectedCounties, main_data, target, val_offset, train_offset))\n",
    "        X_train_val = X_train_val.reset_index(drop=True)\n",
    "\n",
    "        X_test,y_test = np.array(splitData(numberOfSelectedCounties, main_data, target, test_offset, train_offset + val_offset))\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        t2 = time.time()\n",
    "        #print('total time of data splitting: ', t2 - t1)\n",
    "\n",
    "        return X_train_train, X_train_val, X_test, y_train_train, y_train_val, y_test\n",
    "\n",
    "    else:\n",
    "        X_train ,y_train = splitData(numberOfSelectedCounties, main_data, target, train_offset + val_offset, 0)\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "        X_test ,y_test = splitData(numberOfSelectedCounties, main_data, target, test_offset, train_offset + val_offset)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        t2 = time.time()\n",
    "        #print('total time of data splitting: ', t2 - t1)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "r = 14\n",
    "target = 'confirmed'\n",
    "numberOfSelectedCounties = 500  # set to -1 for all the counties\n",
    "\n",
    "data = makeHistoricalData(h, r, target)\n",
    "data = clean_data(data, numberOfSelectedCounties)\n",
    "\n",
    "################################### with validation\n",
    "\n",
    "X_train_train, X_train_val, X_test, y_train_train, y_train_val, y_test = preprocess(data, 1) # with validation\n",
    "\n",
    "# save to csv\n",
    "train_train=pd.concat([X_train_train.reset_index(drop=True),y_train_train.reset_index(drop=True)],axis=1)\n",
    "train_train.to_csv('train_train.csv',index=False)\n",
    "train_val=pd.concat([X_train_val.reset_index(drop=True),y_train_val.reset_index(drop=True)],axis=1)\n",
    "train_val.to_csv('train_val.csv',index=False)\n",
    "test=pd.concat([X_test.reset_index(drop=True),y_test.reset_index(drop=True)],axis=1)\n",
    "test.to_csv('test.csv',index=False)\n",
    "\n",
    "################################# without validation\n",
    "\n",
    "# X_train, X_test, y_train, y_test = preprocess(data, 0) \n",
    "\n",
    "# save to csv\n",
    "# train=pd.concat([X_train.reset_index(drop=True),y_train.reset_index(drop=True)],axis=1)\n",
    "# train.to_csv('train.csv',index=False)\n",
    "# test=pd.concat([X_test.reset_index(drop=True),y_test.reset_index(drop=True)],axis=1)\n",
    "# test.to_csv('test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
